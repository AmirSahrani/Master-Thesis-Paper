\newpage
\chapter{Discussion}
\label{Discussion}
\lhead{\emph{Discussion}}


% Methodological Limitations
% Trust matrix generation mechanisms, e.g. race voice etc.
% Uniform trust between substantative and meta
% 

% Broader implications

% If the Degroot model is accurate, more deliberation would lead to
% substantative agreement, this however is undermind by fishkins "Can
% deliberation have lasting effects", because at least in practice this was
% long and intense, therefore in general it is unreasonable to expect to have
% voters deliberate even longer. 

% This model aligns with that the idea that deliberation pulls extreme opinions
% to middle, such as those from psychology about in-group out-group opinion
% change. There it is established that if groups have little contact they
% become more different
% as each group becomes more alike with-in the group, therefore pull the means of
% the two polarized groups away from each other

% DeGroot model is an insufficient heuristic to model the type of "learning" done
% during deliberation

% Formal model likely unable to fully capture intricacies of interpersonal interaction
% that occurs during deliberation. This is to say, the model might not have predicted
% the change in opinion accurately, but nevertheless we can still learn from this and note
% that deliberation has more complex interactions than a simple weighted linear average.





\section{Conclusion}

We have shown deliberation to be susceptible to strategic manipulation under
various notions of strategic manipulation. Most importantly, we have defined a
new notion of strategyproofness specifically for deliberation over preference
profiles. As a result, we caution that even when deliberation succeeds in
producing single-peaked profiles, it does not guarantee fairness. In the sense
that if all voters had been honest during deliberation, the resulting profile
might have differed. Intuitively, this is expected, as individuals may pretend
to hold more extreme views to shift the general consensus.

Given the idea that  deliberation encompasses more than preferences alone, we
extended our model to deliberation over opinions of voters and alternatives,
through an adaptation of the DeGroot model. We also demonstrated that finding a
voter graph that minimizes the difference between opinion distance and graph
distance is NP-Hard. Suggesting that, in practice, modeling voters on sparse
graphs requires collecting both communication patterns and opinion data. 

Though we were able to replicate the results be
\citet{radDeliberationSinglePeakednessCoherent2021}, we note that the model is
too restrictive, as it only concerns itself with full preferences. We find that
for certain ranges of bias the model behaves chaotically, and introduces cyclic
profiles, even if before the deliberation these were acylic for the KS distance
measure. Given that this model strictly models preferences, we extend it to a 
DeGroot learning model to incorporate opinions in general.

The DeGroot model successfully predicts opinion shifts at the population level
but performs poorly at the level of individual voters. Extending the
simulations to include deliberation on candidate positions, that is, on
meta-opinions, yields profiles with more similar characteristics to the true
preferences. However, after a few iterations, preferences converge too
strongly, resulting in profiles that are less cyclic and more single-peaked
than reality. We note that the development of proximity to single-peakedness
(for both candidate and voter deletion) follows a sigmoid curve, characterized
by a gradual start, a phase of rapid change, and eventual convergence.

Our sensitivity analysis shows that all model parameters influence outcomes.
However, only parameters tied to knowledge and voter count exert strong direct
effects â€” likely because they introduce new information, whereas other
parameters only modulate existing dynamics. In terms of predicting final PBS,
we found that Ego-based bias and knowledge-based trust performed best. Thereby
indicating that more knowledgeable people are more convincing in deliberation,
while people become less likely to change their minds if many people value
their opinion. This is an intuitive result, but as mentioned
\Cref{experiment_results}, we caution that the reason for Ego-based bias
performing well might be (partly) explain by simply reducing the change in
opinions of voters.

In general political elections might elect candidates that will bring about
many changes, most voters however will not have a strong opinion on all of
these. Though we investigated the change in opinion on a per-topic basis, 
we were unable to incorporate this in the preferences over candidates. Given
that most change in opinion was on immigration and healthcare, it might be
the case that these topics were considered more important for this election
and thus more time was spent discussing these. As a result the preferences 
of voters over candidates might be influence more strongly be these topics. 

% - Explain general implications of these results
% 	- Link back to core principles of Deliberation (Honesty etc.)
% 	- Explain how in real life honesty can be safe guarded?
% 	- Put in context of deliberation interventions



\section{Limitations}

\subsection{Applicability of results}
% Practical matters, irrespective of what the model does and does not take into account

While the DeGroot model has been shown to be a more accurate representation of
human belief updating than full Bayesian updating, it does not take into
account why people hold certain beliefs, not does it constraint what kinds of
beliefs a voter can hold at the same time. To remedy this, one might consider a
framework such as abstract argumentation theory (source (DUNG 1995)), as this
is able to model the arguments with the deliberative groups. Though, this seem
theoretically nice, as it allows for formal description on why opinions and
preferences are held, not just descriptions of these facts. From a simulation
based perspective, such a model introduces major validity question. Firstly the
framework requires a map on the relation of all arguments, for this one does
not only need qualitative data, i.e. reported arguments by participants, but
also a method of reliably and accurately transforming these qualitative reports
to argumentative graphs. Secondly, the abstract argumentation framework does
not pose an updating mechanism, thus the method through which participants
would updates their believes using this framework is unclear.

The choice of the DeGroot model assumes that people linearly interpolate between
opinions presented to them. While it has been shown that in some circumstances 
this is a good heuristic, especially when compared to full Bayesian updating. It
does limit the behavior of voters substantially.  
% Now merge into this the section
% on how voters can have contradictory opinions in this model. Also mention mention
% voters might not actually linearly move. An example could be voters having a "threshold"
% for when they would change their mind.

Furthermore, our negative results on strategic manipulation might be remedied
in human deliberation. As fellow participants might be able to sense that
someone is being dishonest. It is also not unreasonable to think that someone
pretending to hold a different opinion, might be worse at defending this
opinion, and therefore be less persuasive.

In the testing of our model, we have consulted a single dataset containing a
large amount of information need. 
However, as a result of not having a single
data set which can fully inform the values in our model, multiple strong
assumptions have been made in order to test the feasibility of the model. We
mention these explicitly once more, as well as how what kind of data might be
collected to inform this and similar models. We formulate this in terms of
missing information on voters and candidates respectively, and present some of
the most important limitations of each.


\subsection{Voter information}
% Issues relating to information we have on the voters

Firstly, we have no access to a data set containing opinions before and after
deliberation as well as the corresponding preference orders. This means having to infer
preferences over candidates, though we chose to do this by minimizing the
distance between the voter and the alternatives, reasonable alternatives exist.
For example, people might use different heuristics to locate a few alternatives
they like best, such as ``Agrees with me on important topics'', thus putting weight on certain issue dimensions. Or they might
simplify each comparison to "Agrees or Disagrees" with me, with some range of
opinion they consider to be in agreement with theirs. 

Furthermore, the way we encode voters' information on alternatives might not
accurately reflect true voters' information. One might expect voters to be more
familiar with candidates close to them in opinion, and thus have less noisy
estimates of these candidates' positions. 

Finally,  the error of voters' estimates might not be normally distributed. In
a polarized election, it is not unreasonable to expect errors on the
``opposing'' party to skew further way from that voters' opinion.


\subsection{Candidates}
% Issues we have realting to information we have on candidates (which is effectively no information)

Though datasets such as those by Ipsos might contain the scores of political
parties, these datasets cannot (easily) be combined with the data used in this
study. This is mostly due to the inconsistent formats of the questions and the
included topics. As a result, we are required to generate candidates manually.
Thereby not only introducing another modeling choice, but also discarding an
important piece of information. The \textsc{America in One Room} dataset does
contain voters' most preferred candidate, which is either the Democratic or
Republican Party or Independent (participants are not asked to further
specify). But lacking information on the candidates true positions as well as
the ranking over the others, this information is hard to incorporate within the
model. 

Instead, we chose a simple approach, either selecting a single
voter, or grouping some voters together as a single candidate. In the real
world, however, candidates might arise in different ways and forms. For
example, they could bring new idea's, not measured in the poll, or gather
like-minded people instead of catering to the entire voting population, indeed
the latter seems to be point of representative democracies. In representative
democracies candidates represent specific demographics of the population, and
advocate for their interests.


\subsection{Extentions}
% First extend model in terms of deliberation, then possibly as a model of population


Given the weak performance of the model, a better computational model is needed
to understand deliberation and inform the design of deliberative interventions.
We propose some extensions to the model, which might better capture human
dynamics.

When humans deliberate, the amount of trust placed on each person is likely not
fixed, for example, if someone has convinced a voter to change their mind on
multiple topics, this voter might be more likely to trust them on a new topic
as well. Or on the contrary, if two voters consistently disagree, and diverge
in their opinions, they might come to trust each other less. Furthermore, the
development of trust will likely differ between people, both on their baseline
and development of their trust. Though we do not propose a specific updating
scheme for this, the model is flexible enough to allow for the updating of the
trust matrix over time. 


If we extend this model to model large population, for example using a social
network, it is crucial to be able to assess the effects disruptive events such
as a national health crisis, an economic recession or a national safety threat.

As a result of such an event subset of the voters might become more informed on the position of
the candidates, as the event might cause information dispersal, for example
through news networks. This limitation is related to the notion of
\textit{Salience} as described by
\citet{listDeliberationSinglePeakednessPossibility2013}, stating that topics
with high salience benefit less from deliberation, as participants have likely
received more information on this topic. Though this could, at least in
principle, be resolved by constructing trust matrices for individual topics.
This would raise further questions as to the validity of these matrices.
