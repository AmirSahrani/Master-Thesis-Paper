\newpage
\chapter{Experimental Results}
\label{experiment_results}
\lhead{\emph{Experimental Results}}
We first present a full replication and extension of the work by
\citet{radDeliberationSinglePeakednessCoherent2021}\footnote{This is omitted
for this week's meeting.}. Then we present the simulations based on our model of
meta-deliberation, as well as the results of the sensitivity analysis on both
models. All code for the replication, main experiment and visualizations can be
found in \href{https://github.com/amirsahrani/master_thesis}{this Repository}.
%
%
% \section{Replication} We are able to fully replicate the results found by
% \citet{radDeliberationSinglePeakednessCoherent2021},  in \Cref{fig:rep_cyclic}
% we see that while the bias is less than 0.73, all metric results in a-cyclic
% preferences. We also replicate the behavior of the KS metric, where biases in
% the range of 0.73-0.85, show even some initial a-cyclic profiles can become
% cyclic. \Cref{fig:rep_count} Further explains this by showing that within this
% range we always observe 3 unique profile for the KS metric, while DP and CS
% have already settled on 6 profiles, thereby representing all possible
% preferences. \Cref{fig:rep_condorcet} shows KS introduces ambiguity in the case
% that there was a Condorcet winner, resulting in losing the original nice
% profile. Finally, the proximity to single-peakedness shows a slightly more
% positive note for the KS metric, showing that while the DP and CS bottom out to
% the minimum proximity to single-peakedness, KS stays relatively close. Though
% this should be taken with a grain of salt, as it is likely a consequence of the
% unique preferences being smaller.
%
% \begin{figure}[htbp]
% 	\centering
% 	\begin{minipage}{0.45\textwidth}
% 		\centering
% 		\includegraphics[width=\textwidth]{Figures/cyclic_proportion_Proportion.pdf}
% 		\caption{The proportion of cyclic profiles remaining, 0 indicating that no cyclic profiles were present after deliberation.}
% 		\label{fig:rep_cyclic}
% 	\end{minipage}\hfill
% 	\begin{minipage}{0.45\textwidth}
% 		\centering
% 		\vspace{-9pt}
% 		\includegraphics[width=\textwidth]{Figures/unique_Unique Preferences.pdf}
% 		\caption{Number of unique preferences at the final step of deliberation.}
% 		\label{fig:rep_count}
% 	\end{minipage}
%
% 	\vspace{1em}
%
% 	\begin{minipage}{0.45\textwidth}
% 		\centering
% 		\includegraphics[width=\textwidth]{Figures/condorcet_proportion_Proportion.pdf}
% 		\caption{The proportion of Condorcet winners left after deliberation, value above one indicate Condorcet winners emerging during deliberation}
% 		\label{fig:rep_condorcet}
% 	\end{minipage}\hfill
% 	\begin{minipage}{0.45\textwidth}
% 		\centering
% 		\vspace{-9pt}
% 		\includegraphics[width=\textwidth]{Figures/sp_proximity_PtS.pdf}
% 		\caption{Proximity to single-peakedness after deliberation. Proximity to single-peakedness as defined in \Cref{section:related_work}.}
% 		\label{fig:rep_single_peaked}
% 	\end{minipage}
% \end{figure}
% \newpage

\section{DeGroot Model}
\label{degroot_results}
\subsection{Optimal parameters}

Between the deliberation group and the control group, if we look at the final
time step, we find that both perform best if the bias is set to be around 1,
though this differs based on the other parameters. This seems to indicate that
for both smaller and larger groups, a voter's opinion is in some sense equally
important as the of  \textit{all} other voters she comes in contact with. In
other words, it does not seem to matter how many people disagree with a voter,
her own opinion holds a constant relative importance.

Looking at the deliberation group, we show the best bias values in the following table:
\begin{table}
	\begin{center}
		\begin{tabular}{lccc}
			\toprule
			Candidate Generator & $P_{v}$            & $P_{c}$           & Total             \\
			\midrule
			Sample              & 0.10, $\kappa = T$ & 0.70, $\kappa =F$ & 0.10, $\kappa =T$ \\
			Voter               & 0.90, $\kappa =F$  & 0.70, $\kappa =T$ & 0.50, $\kappa =F$ \\
			\bottomrule
		\end{tabular}
		\caption{Each cell contains the optimal bias value for the configuration as well as if it is better to use knowledge based trust in the deliberation condition.}\label{tab:opt_delib}
	\end{center}
\end{table}
\begin{table}
	\begin{center}
		\begin{tabular}{lccc}
			\toprule
			Candidate Generator & $P_{v}$    & $P_{c}$     & Total      \\
			\midrule
			Sample              & 0.50, True & 0.40, False & 0.40,False \\
			Voter               & 0.10, True & 1.50, True  & 1.50, True \\
			\bottomrule
		\end{tabular}
		\caption{Each cell contains the optimal bias value for the configuration as well as if it is better to use knowledge based trust in the control condition.}\label{tab:opt_control}
	\end{center}
\end{table}

\begin{figure}
	\centering
	\begin{minipage}{0.45\textwidth}
		\begin{center}
			\includegraphics[width=\textwidth]{Figures/error_scatter_delib.pdf}
		\end{center}
		\subcaption{The distribution of errors in the deliberation condition}
	\end{minipage}
	\hspace{1em}
	\begin{minipage}{0.45\textwidth}
		\begin{center}
			\includegraphics[width=\textwidth]{Figures/error_scatter_control.pdf}
		\end{center}
		\subcaption{The distribution of errors in the control condition}

	\end{minipage}
	\caption{}\label{fig:bias_over_time}
\end{figure}


Here it is clear that generally the model performs best when both the number of
candidates and the number of voters are low. We also not that though the error
of the different candidate generators are comparable, they in general the
Sample methods seems to results in larger errors, meaning that the model is
less well able to capture circumstances where the alternative's opinions are
not represented in the deliberating population. Finally, we see that The
distribution of best biases skews to values around 1.3, thus indicating that
even while deliberating, people tend to hold their opinion to be \textit{more}
important than that of all other voters.

We investigate this discrepancy between the two candidates generation methods
now, to this end we look at the difference in error for all tested
configuration.

% Now we T test on everything the Sample and Voter method

\subsection{Convergence}

From \Cref{theory}, we have seen that in the limit some matrices are
convergent, while some are not, in particular if the matrix is aperiodic, this
it is convergent. For the matrices in these simulations, we cannot guarantee
aperiodicity. Thus, we resort to the following, instead of looking at the
matrices directly, we instead look at the distance between the estimated
support matrix, and the true support matrix, where the distance in the element
wise $\ell_2$ norm. We do the same for the support vectors and the true
opinions.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{Figures/convergence_groups.pdf}
	\end{center}
	\caption{Convergence of different distance metrics as well as the
		$\ell_1$-norm between the trust matrix at the start and time step
		t}\label{fig:convergence_big}
\end{figure}



We find the error of the model in terms of both the KS and CS distance to be minimal in the case where we use the original groups and use the voters' knowledge to inform the trust matrix. We can clearly see that uniform trust is an unrealistic when we do not adhere to the original group. Interestingly, simply using the original group labels improves the model, showing that the groups might not be exactly the same.

We now proceed to look at distance to single-peaked profiles, look at both
voter removal and candidate removal. We show that for optimal bias, as
deliberation progresses we see an increase in the proximity to single
peakedness.

