\chapter{Methods}
\label{Methods}
\lhead{\emph{Methods}} % Set the left side page header to "Symbols"



This section presents our experimental methodology in three parts. First, we
replicate the preference-based deliberation model of
\citet{radDeliberationSinglePeakednessCoherent2021} to establish baseline
measurements. Second, we develop and validate the adapted DeGroot model using
data from the \textsc{America in One Room} experiment. Finally, we apply this validated
model to generate synthetic preference profiles and analyze their structural
properties.

All experiments are
implemented using OCaml and Python. Data sources and ethical considerations are
detailed in \Cref{ethics_data}, all code can be found at \url{https://github.com/amirsahrani/master_thesis}.


\section{Replication of \citet{radDeliberationSinglePeakednessCoherent2021}}

We implement the model as described in \Cref{section:related_work}. Agents are
limited to strict preferences over all candidates. All experiments are done with
3 candidates, and 51 voters. The number of voters is chosen to be an odd number
to prevent perfect ties. Each voter receives a random strict preference, created
by permuting the candidates. All voters share the same bias factor. The order of
deliberation is decided randomly, by shuffling the voters. Bias is varied
between 0.45 and 0.99 (exclusive) in steps of 0.1, for each bias factor we run 100
simulations, for a total of 5400 simulations.


We measure evaluations relating to strict preferences, namely the
proportion of cyclic profiles, the number of unique profiles and the proximity
to single-peakedness by voter deletion (PtS-V), all as reported by
\citet{radDeliberationSinglePeakednessCoherent2021}. In addition to those, we
also measure the frequency of Condorcet winners. We do this to see if cyclic
profiles might be hiding some agreement, where the majority relation might have a clear winner, while still being cyclic. We do not measure the PtS-C, as any
profile with 2 candidates is single-peaked and the simulation will have 3
candidates, all values would trivially be either 1 or $\frac{2}{3}$.  This metric therefore
provides little additional insight.

Due to the computational complexity of the
DP-metric, as well as the calculation of PtS-V, a larger number of candidates is not
feasible. Specifically, PtS-V is NP-complete
\cite{erdelyiComputationalAspectsNearly2013}, though it allows for a
2-approximation. We use the method based on an ILP solver, as implemented in
\texttt{PrefTools} \cite{PrefLibPreflibtools2025}.



\section{Adapted DeGroot}
We use the adapted DeGroot model as laid out in \Cref{sec: main model} to capture deliberation dynamics. This model requires realistic trust matrices, we propose three mechanisms through which we can construct these.


\textbf{Knowledge}. We consider knowledge as a factor that can influence both the trust a voter places in others and the confidence they have in their own opinion. Let $\boldsymbol{k}$ denote a vector, where each $k_i$ represents a knowledge score for voter $i$. This score may inform a voter's bias towards their own opinion, under the assumption that greater knowledge increases confidence.

There are two plausible interpretations of how knowledge affects self-bias. On
one hand, more knowledgeable voters may be more confident and thus less
susceptible to influence. On the other hand, increased knowledge might make
voters more aware of the limits of their understanding—capturing the essence of
the Dunning-Kruger effect, where individuals with limited knowledge fail to
recognize their own ignorance. However, in the context of direct deliberation,
we argue that the latter interpretation is less realistic: ideally, as
deliberation progresses voters are exposed to new information and opposing
viewpoints, making them more aware of the knowledge boundaries of their peers
as well as their own. Thereby allowing voters to place more weight on voters
more knowledgeable than them.

Regarding trust in others, we follow a similar line of reasoning: voters are
more likely to trust peers who exhibit higher levels of knowledge. We assume
that expertise becomes apparent during discussion, leading to increased
trust in more knowledgeable individuals


\textbf{Similarity}. A voter might trust people more if they are similar to them, in this work we take similarity to mean a similarity in substantive opinion. It is however not hard to conceive of similarity influence trust in other ways such as social status.


\textbf{Ego}. Finally, a voter may place greater weight on her own opinion if
she is highly trusted by others.

Finally, we allow for a bias factor, similar to Rad and Roy, in order to
directly affect the self-loop in the trust matrix.

Selecting among these mechanisms is ultimately an empirical question, which we explore in \Cref{experiment_results}.

Given each notion of trust, we define the full model using matrix operations,
including elementwise (Hadamard) products. Hadamard products are entry wise
multiplications of matrices. First, we define $T_{\text{out}}$ as follows,

\begin{equation}
	T_{\text{out}} = A \odot  K \odot S
	\label{eq:mat_out_trust}
\end{equation}

Here $A$ is the adjacency matrix of shape $n \times n$, without self loops. $K$
is the matrix of knowledge scores of shape $n \times n$ with each row being
the vector of knowledge scores $\boldsymbol{k}^T$, such that each $K_{ij} =
	\boldsymbol{k}_j$. $S$ is the similarity matrix, where $S_{ij} = 1 - d_{ij}$,
and $d_{ij}$ is the normalized $\ell_1$ distance between voters $i$ and $j$’s
opinions. The normalization ensures the maximum distance is 1, so that $S_{ij}
	\in [0, 1]$.

Next, we compute the vector $T_{\text{in}}$, which represents each voter’s internal (self-)trust or bias:

\begin{equation}
	T_{\text{in}} = (T_{\text{out}} \boldsymbol{b}) \odot \boldsymbol{k} \odot \boldsymbol{e}
	\label{eq:in_trust}
\end{equation}

Here $\boldsymbol{b}$ is a vector of length $n$ containing the bias factor in each entry,
and $T_{\text{out}} b$ is a standard matrix-vector product yielding a column
vector that captures the total external influence received, scaled by the
voter's bias. $\boldsymbol{k}$ is the column vector of knowledge scores, and
$\boldsymbol{e}$ is the ego vector, computed as $\boldsymbol{e} = T_{\text{out}}^\top
	\boldsymbol{1}$, where $\boldsymbol{1}$ is the all-ones vector. This represents
the total trust each voter receives from others


Finally, we construct the full trust matrix $T$ by combining $T_{\text{out}}$ with the diagonal matrix formed from $T_{\text{in}}$, and normalize each row so that trust weights sum to 1:


\begin{equation}
	T = \operatorname{norm}\left(\operatorname{diag}(T_{\text{in}}) + T_{\text{out}}\right)
	\label{eq:final_trust}
\end{equation}

Here $+$ denotes element-wise addition, and $\operatorname{norm}$ normalizes the rows of the resulting matrix so that $\sum_j T_{ij} = 1$ for all $i$.


In this model, we make the simplifying assumption that trust remains static
over time. While this is likely an unrealistic assumption, the absence of data on
trust dynamics during deliberation prevents us from empirically modeling its
evolution. Although we refrain from speculating in detail on how this
assumption could affect the general conclusions, we note it might affect both
the rate of convergence, and the equilibrium reached.

Given this formulation, we define an instance of our model through shaping the
matrices, such as shown in example \Cref{ex:degroot_matrix_definition}.

\begin{example}{DeGroot deliberation Instance}{degroot_matrix_definition}

	Consider a setting with three voters. Let us define the following matrices:

	\begin{align}
		A = \begin{bmatrix}
			    0 & 1 & 1 \\
			    1 & 0 & 1 \\
			    1 & 1 & 0 \\
		    \end{bmatrix} \quad
		K = \begin{bmatrix}
			    0.5 & 1 & 2 \\
			    0.5 & 1 & 2 \\
			    0.5 & 1 & 2 \\
		    \end{bmatrix}\quad
		S = \begin{bmatrix}
			    0   & 0.5 & 1 \\
			    0.5 & 0   & 1 \\
			    1   & 1   & 0 \\
		    \end{bmatrix}\quad
	\end{align}

	Note that the adjacency matrix $A$ has no self loops, $K$ has repeating
	rows, and $S$ is symmetric, as the similarity of voter $i$ to voter $j$
	must be the same as the other way round.

	Now suppose we want to create a trust matrix $T$, that uses knowledge for the
	outgoing trust, but not the similarity. Uses a constant bias
	factor of 2, and Ego-based trust, but not self-knowledge. To achieve
	this, we redefine matrix $S$ as follows, noting that $A$ handles the self-loops,

	\begin{align}
		S = \begin{bmatrix}
			    1 & 1 & 1 \\
			    1 & 1 & 1 \\
			    1 & 1 & 1 \\
		    \end{bmatrix}\quad
	\end{align}

	Taking the element-wise product of these matrices yields:

	$$T_{\text{out}} = \begin{bmatrix}
			0   & 1 & 2 \\
			0.5 & 0 & 2 \\
			0.5 & 1 & 0 \\
		\end{bmatrix}$$

	Next, we compute $T_{\text{in}}$:
	$$T_{\text{in}} = \begin{bmatrix}
			6 \\
			5 \\
			3 \\
		\end{bmatrix} \odot
		\begin{bmatrix}
			1 \\
			2 \\
			4 \\
		\end{bmatrix} = \begin{bmatrix}
			6  \\
			10 \\
			12 \\
		\end{bmatrix} $$

	Here the first vector is the result of each row sum of $T_{\text{out}}$ by the bias factor (2), and the second vector is the ego vector, i.e., the sum of the columns in $T_{\text{out}}$.

	The trust matrix before normalization is then:
	$$\begin{bmatrix}
			6   & 1  & 2  \\
			0.5 & 10 & 2  \\
			0.5 & 1  & 12 \\
		\end{bmatrix}$$
	Which we then normalize to get:
	$$T = \begin{bmatrix}
			\frac{2}{3}  & \frac{1}{9}   & \frac{2}{9}   \\
			\frac{1}{25} & \frac{20}{25} & \frac{4}{25}  \\
			\frac{1}{27} & \frac{2}{27}  & \frac{24}{27} \\
		\end{bmatrix}
	$$
\end{example}



\section{Model Validation}

We split the experiments on the adapted DeGroot model into two parts. Firstly,
we aim to assess the validity of the model. We use data from the
\textsc{America in One room} experiment, focusing on the deliberation group.
The control group in this data set shows no significant difference, thus the
only sensible trust matrix is the identity matrix. This dataset does not
provide full preference rankings over the candidates, instead provides data on
voters' opinions on 6 different topics of political discussion, such as climate
change and immigration. This data provides knowledge scores for each voter as
measured by a set of seven questions relating to governmental institutions. We
construct the knowledge scores as the fraction of correct answers. Using these
opinions, we assess the validity of the model insofar as it is able to
accurately predict the final opinion of voters. This we measure for each voter,
as well as for binned groups of voters with similar opinions. The latter
measurement replicating the assessment by
\citet{fishkinCanDeliberationHave2024}, where voters a placed in fixed size bins such that each bin contains voters with similar initial PBS.

We run 5000 simulations, randomizing the independent variables laid out in
\Cref{tab:independent_variables}, excluding \texttt{Candidates}, and
\texttt{Candidate Generator}. We then use an ANOVA to test for the
configuration of trust matrices that minimizes the absolute errors in predicted
policy based-ideology score. Since the original data provides group numbers for
the participants, we also experiment with
replicating these groups as opposed to randomly grouping voters together. When
using the original groups, the \texttt{number of voters parameter} is ignored.

We acknowledge that using the same dataset for both parameter estimation and
validation may lead to overfitting. This represents a limitation imposed by
data availability, as the \textsc{America in One Room} experiment is the only
large-scale deliberation dataset with the necessary pre- / post-measurements/post measurements and
knowledge scores to which we had access.





Finally, we use sensitivity analysis to investigate which parameters have the
strongest effect on the variance of the model's prediction error. Using Sobol
indices and a sample size of 4096, we use the same ranges during the validation and sensitivity analysis. We calculate the first, second, and total
order effects. The first order indices refer to their direct effects on the
variance of the model, while all other parameters are varied randomly. The second and
total order capture this for pairwise interactions of a variable and for all
first- and higher-order interactions of a variable, respectively.


\renewcommand{\arraystretch}{1.2}
\begin{table}
	\centering
	\begin{tabular}{lp{0.4\linewidth}l}
		\toprule
		Parameter                     & Description                                                         & Values                      \\
		\midrule
		\texttt{Number of Voters}     & The number of voters in the simulation.                             & 9,  13, \dots,29*           \\
		\texttt{Number of Candidates} & The number of candidates to be voted on.                            & 3, 4, 5, 6, 7               \\
		\texttt{Candidate Generator}  & The method used to generate candidates.                             & Sample, single random voter \\
		\texttt{Bias}                 & The bias all voters have towards their own opinion.                 & 0.8, 1.0, \dots, 2.8*       \\
		\texttt{Time steps}           & The number of deliberation ``steps'' the voters undergo.            & 1, 2, \dots, 20             \\
		\texttt{Group}                & Use the original groups.                                            & True/False$^\dagger$        \\
		\texttt{Similarity}           & Distribute trust based on similarity.                               & True/False*                 \\
		\texttt{Knowledge}            & Distribute trust based on knowledge.                                & True/False*                 \\
		\texttt{Ego}                  & Scale voters' bias according to the trust other people have in them & True/False*                 \\
		\texttt{Self-Knowledge}       & Scale voters' bias according to their knowledge                     & True/False*                 \\
		\bottomrule
	\end{tabular}
	\label{tab:independent_variables}
	\caption{The parameters of the adapted DeGroot model and their values. Parameters marked with asterisk are randomized during sensitivity analysis. $\dagger$ Set to False during sensitivity analysis.}
\end{table}


\section{Adding Meta-Agreement}

Using these results we expand the model to
incorporate meta-agreement on alternatives, for this we need to generate
potential candidates. This is done either by selecting a voter and creating a
candidate with identical opinions, or by selecting 10 voters with replacement
and creating an average of their opinions. We derive voters’ preference
rankings over the simulated candidates based on $\ell_1$ distances between
their opinions. We run 1000 random simulations, assessing the same metrics as in the Rad and Roy replication,
namely whether the final profiles are cyclic, whether they have a Condorcet
winner, the number of unique profiles, and their PtS-V, and finally we also
measure PtS-C. The PtS-C can be calculated in $\mathcal{O}(|V| \cdot{} |C|
	^3)$\cite{przedmojskiAlgorithmsExperimentsNearly}, though the implementation we
use is that of the \texttt{PrefTools} library \cite{PrefLibPreflibtools2025},
which implements a slower $\mathcal{O}(|V| \cdot{} |C|^5)$ algorithm
\cite{erdelyiComputationalAspectsNearly2013}.


