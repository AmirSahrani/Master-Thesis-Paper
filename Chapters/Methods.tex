\chapter{Methods}
\label{Methods}
\lhead{\emph{Methods}} % Set the left side page header to "Symbols"



We proceed with the methods used to replicate the paper by
\citet{radDeliberationSinglePeakednessCoherent2021}, as well as the
experimental setup of our own model. Links to the data used for these
experiments can be found in \Cref{ethics_data}. The programs
are implemented using \texttt{OCaml}, and \texttt{Python}.


\section{Replicating Rad and Roy} We implement the model as described in
\Cref{section:related_work}. Agents are limited to strict preferences over all
candidates. All experiments are done with 3 candidates, and 51 voters. The
number of voters is chosen to be an odd number, as this prevents ties between
candidates. We measure evaluations relating to strict preferences, namely the
proportion of cyclic profiles, the number of unique profiles and the proximity
to single-peakedness by voter deletion (PtS-V), all as reported by
\citet{radDeliberationSinglePeakednessCoherent2021}. In addition to those we
also measure the frequency of Condorcet winners. We do this to see if cyclic
profiles might be hiding some agreement, where voters might be able to agree on
a winner, but not on the full ranking. We do not measure the PtS-C, as any
profile with 2 candidates is single-peaked. Since the simulation will have 3
candidates, all values would be either 1 or $\frac{2}{3}$, therefore this metric
would be of little added value. Due to the computational complexity of the
DP-metric, as well as the calculation of PtS-V, a larger number of candidates is not
feasible. Specifically PtS-V is NP-complete
\cite{erdelyiComputationalAspectsNearly2013}, though it allows for a
2-approximation. We use the method based on an ILP solver, as implemented in
\texttt{PrefTools} \cite{PrefLibPreflibtools2025}

Using these results we aim to show the limitations of preference based deliberation.

\section{Experiments}
We aim to replicate the findings by the \textsc{America in One room}
experiments \cite{fishkinCanDeliberationHave2024} in-silico. To this end we
use the adaption to the DeGroot model as laid out in \Cref{sec: main model}
The dataset contains a control group as well as an experimental group. The control group shows no change in opinion over time,
thus this group is best modelled by using the identity matrix $I^n$ as the
trust matrix. The experimental group is modelled as a densely connected
network.  The distribution of the trust we control through 3 methods.

\subsection{Modelling Trust} We propose three different mechanisms through which we
will the trust matrix, as well as the intuitive and theoretical
appeal.


\textbf{Knowledge}. Firstly we consider knowledge, this can be used to
inform both the trust in others, and your bias towards yourself. For this we
can imagine a vector $\boldsymbol{k}$, where each $k_i$ contains some knowledge
score for voter $i$. In modeling, we now have 2 options, firstly, does a voters
knowledge affect their bias towards their own opinion. Intuitively one could
reasonably argue either way. Two plausible ways of reasoning are, ``A
knowledgeable voter knows more facts and is therefore harder to convince'', or
``A Knowledgeable voter realizes the complexity of the topic and is therefore
less certain''. The first line of reasoning seems more general, as it seems
independent of the topic at hand. However, the second line of reasoning seems
to capture something like the Dunning-Kruger effect, which states that people
can have ``meta-ignorance'', meaning they do not realize what they do not realize.

As for the trust a voter places in their peers, a similar argument can be made,
where the voter could either place more trust on people that are more
knowledgeable, and thereby might be able to provide more facts. Or less
knowledgeable voters might be more persuasive in making strong an bold claims,
as without strong knowledge on the subject voters are more likely to hold
strong opinions SOURCE

% Or they could
% trust less knowledgeable people more because their ignorance allows them to
% make more confidant claims, even if these are inaccurate.


\textbf{Similarity}. A voter might trust people more if they are similar to them, in this work we take similarity to mean a similarity in substantive opinion. It is however not hard to conceive of similarity influence trust in other ways such as social status.

% Voters might simply trust people with
% similar opinions more, representing a sort of confirmation bias. This cannot be
% applied to ones own opinion in the same sense as with the other two methods.
% This could be represented as a sort of ``general bias'', where a voter is more
% or less inclined to listen to other opinions.

\textbf{Ego}. Finally, a voter might be less inclined to change her opinion if
more people value it.

Given these different options, the right selection of methods becomes question
for empirical observation, which we present in the next Chapter.

Firstly, and most simply, we give all voters a bias. This bias reflects how
much of their trust they place on themselves. For example a bias of 1
represents them placing equal trust on themselves as all other voters combined.
The actual weight on the self loop is calculated as the sum of all incoming
edges multiplied by the bias. Secondly, we have knowledge-based trust, in which
a voter trusts voter $j$ more if voter $j$ is more knowledgeable. We get the
knowledge scores from the \textsc{America in One room} dataset by taking the
proportion of knowledge questions they answered correctly. The interpretation
is that more knowledgeable voters would be more persuasive and thus be more
influential on other voters' opinions. Thirdly, we have credibility-based
trust, where the trust a voter places on another voter is proportional to the
number of outgoing edges that second voter has. This method becomes equivalent
to placing uniform trust in all voters when all voters are situated in a fully
connected graph. If we do not use credibility- or knowledge- based trust, we
call this uniform trust, meaning that they treat all neighbors the same.
Importantly, this does not imply any specific bias value.

Given these matrices we can define the full model in terms of matrix and
Hadamard products, where Hadamard products are entry wise multiplications of
matrices. First we define $T_{\text{out}}$ as follows,

\begin{equation}
	T_{\text{out}} = A \odot  K \odot S
	\label{eq:mat_out_trust}
\end{equation}

Where $A$ is the adjacency matrix, without any self loops, $K$ is the matrix of knowledge scores, and $S$ is the matrix of similarity between each voter. We use the indicator functions $\mathds{1}$ for both knowledge and similarity.

In order to determine the bias of each voter we use the matrix $T_{\text{out trust}}$, to generate $T_{\text{in}}$ as follows,

\begin{equation}
	T_{in} = (T_{\text{out}} b) \odot \operatorname{diag}(K) \odot E
	\label{eq:in_trust}
\end{equation}

Where $b$ is a vector of length $n$ containing the bias factor in each entry,
$K$ is the knowledge matrix, from which we extract the diagonals, and $E$ is
the ego matrix defined as $T_{\text{out}}^T [1]^n$, thereby getting the sum of
all incoming edges.

Through some abuse of notation we can now define the final trust matrix $T$ as the diagonal matrix obtained from $T_{\text{in}}$ and its element wise addition with $T_{\text{out}}$:

\begin{equation}
	T = \operatorname{norm}\left(\operatorname{diag}(T_{\text{in}}) \oplus T_{\text{out}}\right)
	\label{eq:final_trust}
\end{equation}

Were $\operatorname{norm}$ normalizes the matrix such that each row sums to exactly 1.


Given this formulation, we define an instance of our model through shaping the
matrices, such as shown in example \Cref{ex:degroot_matrix_definition}.

\begin{example}{DeGroot deliberation Instance}{degroot_matrix_definition}

	Say we have the following matrices:
	\begin{align}
		A = \begin{bmatrix}
			    0 & 1 & 1 \\
			    1 & 0 & 1 \\
			    1 & 1 & 0 \\
		    \end{bmatrix} \quad
		K = \begin{bmatrix}
			    0.5 & 1 & 2 \\
			    0.5 & 1 & 2 \\
			    0.5 & 1 & 2 \\
		    \end{bmatrix}\quad
		S = \begin{bmatrix}
			    0   & 0.5 & 1 \\
			    0.5 & 0   & 1 \\
			    1   & 1   & 0 \\
		    \end{bmatrix}\quad
	\end{align}

	Note that $A$ has no self loops, $K$ repeats its rows, since each voter has 1
	knowledge score, and $S$ must be symmetric, as the similarity of voter $i$
	to voter $j$ must be same as the other way round.

	Now we want to create a trust matrix $T$, that uses knowledge for the outgoing trust, but not the similarity. For the bias it used a bias factor of 2, and uses Ego, it does not use self knowledge. To achieve this we define the following matrices,

	\begin{align}
		K' = \begin{bmatrix}
			     0   & 1 & 2 \\
			     0.5 & 0 & 2 \\
			     0.5 & 1 & 0 \\
		     \end{bmatrix}\quad
		S' = \begin{bmatrix}
			     1 & 1 & 1 \\
			     1 & 1 & 1 \\
			     1 & 1 & 1 \\
		     \end{bmatrix}\quad
	\end{align}

	If we now use $K'$ and $S'$, we see that $T_{\text{out}}$ is not
	affected by the change from $K$ to $K'$ since the diagonals remain 0,
	and $S'$ now has no influence on the trust. As a result we get:

	$$T_{\text{out}} = \begin{bmatrix}
			0   & 1 & 2 \\
			0.5 & 0 & 2 \\
			0.5 & 1 & 0 \\
		\end{bmatrix} = K'$$

	As a result, $T_{\text{in}}$ now becomes:
	$$T_{\text{in}} = \begin{bmatrix}
			6 \\
			5 \\
			3 \\
		\end{bmatrix} \odot
		\begin{bmatrix}
			1 \\
			2 \\
			4 \\
		\end{bmatrix} = \begin{bmatrix}
			6  \\
			10 \\
			12 \\
		\end{bmatrix} $$

	The final trust matrix $T$ is then:
	$$T = \begin{bmatrix}
			6   & 1  & 2  \\
			0.5 & 10 & 2  \\
			0.5 & 1  & 12 \\
		\end{bmatrix}$$
	Which we then normalize to be:
	$$T = \begin{bmatrix}
			\frac{2}{3}  & \frac{1}{9}   & \frac{2}{6}   \\
			\frac{1}{25} & \frac{20}{25} & \frac{4}{25}  \\
			\frac{1}{27} & \frac{2}{27}  & \frac{24}{27} \\
		\end{bmatrix}
	$$

\end{example}

\subsection{Outcome measures}

We split the experiments on the adapted DeGroot model into two parts. Firstly,
we aim to assess the validity of the model. For this we use data from the
\textsc{America in One room} experiment. This data does not provide full
preference rankings over the candidates, instead provides data on voters'
opinions on 6 different topics of political discussion, such as climate change
and immigration. Using these opinions, we assess the validity of the model in
so far as it is able to accurately predict the change in opinion. We run 5000
simulations, randomizing the independent variables laid out in \Cref{tab:
	indepdent_variables}, excluding \texttt{Candidates}, and \texttt{Candidate
	Generator}. We then use an ANOVA to test for the configuration of trust
matrices that minimizes the errors in predicted PBS. Since the original data
provides group numbers for candidates who participated in the deliberation, we
also experiment with replicating these groups as opposed to randomly grouping
voters together.


Using these results we expand the model to incorporate meta-agreement on
alternatives, for this we need to generate potential candidates. This is done
either by selecting a voter and creating a candidate with identical opinions,
or by selecting 10 voters with replacement and creating an average of their
opinions. Using these simulated candidates we are able to create preference
rankings using the $\ell_1$-norm. We measure whether the same outcomes as in the Rad and Roy replication section, namely whether the final profiles are cyclic, whether they have a Condorcet winner, home many unique profiles there
are, and their PtS-V, and finally we also measure PtS-C. The PtS-C can be calculated in
$\mathcal{O}(|V| \cdot{} |C| ^3)$\cite{przedmojskiAlgorithmsExperimentsNearly},
though the implementation we use is that of the \texttt{PrefTools} library
\cite{PrefLibPreflibtools2025}, which implements a slower $\mathcal{O}(|V|
	\cdot{} |C|^5)$ algorithm \cite{erdelyiComputationalAspectsNearly2013}.




% We aim to find values for all parameters that minimize the error of the model,
% conditional on the number of voters and candidates. For this we define the
% error of our model as the (normalized) difference of the proportion of cyclic
% profiles, the proportion of simulation containing a Condorcet winner, and the
% proximity to single-peakedness through voter deletion, and the
% candidate-based notion. With these parameters, we argue that model captures the
% learning process. We then proceed to analyze convergence behavior under these
% optimal parameters. For this analysis, all configurations are run 100 times.


\renewcommand{\arraystretch}{1.2}
\begin{table}
	\centering
	\begin{tabular}{p{4cm}p{0.65\linewidth }}
		\toprule
		Parameter                     & Description                                                                                                                                                                 \\
		\midrule
		\texttt{Number of Voters}     & The number of voters in the simulation, representing either the deliberation group, or the control population.                                                              \\
		\texttt{Number of Candidates} & The number of candidates to be voted on.                                                                                                                                    \\
		\texttt{Candidate Generator}  & The way the candidates are generated. Either a random voter is selected for each candidate, or 10 random voters (sampled with replacement) get averaged into one candidate. \\
		\texttt{Bias}                 & The bias all voters have towards their own opinion.                                                                                                                         \\
		\texttt{Time steps}           & The number of deliberation ``steps'' the voters undergo.                                                                                                                    \\
		\texttt{Group}                & Use the original groups.                                                                                                                                                    \\
		\texttt{Similarity}           & Distribute trust based on credibility.                                                                                                                                      \\
		\texttt{Knowledge}            & Distribute trust based on knowledge.                                                                                                                                        \\
		\texttt{Ego}                  & Scale voters' bias according to the trust other people have in them                                                                                                         \\
		\texttt{Self-Knowledge}       & Scale voters' bias according to their knowledge                                                                                                                             \\
		\bottomrule
	\end{tabular}
	\label{tab: indepdent_variables}
	\caption{The parameters of the DeGroot learning based model, as well as their descriptions}
\end{table}


Finally, we use sensitivity analysis to investigate which parameters have the
strongest effect on the variance of model, using Sobol indices to get the
first, second and total order effects. The first order indices refer to their
direct effects on the variance of the model, when all other parameters are
randomized. The second and total order capture this for 2-way interactions of
variable and all interactions of a variable respectively.

