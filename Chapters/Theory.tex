\newpage \chapter{Theory} \label{theory}

\lhead{\emph{Theory}} % Set the left side page header to "Symbols"

In the model of deliberation by
\citet{radDeliberationSinglePeakednessCoherent2021}, outlined in
\Cref{section:related_work}, they aim to model deliberation and show that
deliberation results in nicely structured profiles which allow for strategy
proof voting rules. One important caveat, given by the authors as well, is all
participants should honestly and truthfully participate in deliberation. We now
provide a formal statement, showing deliberation does not prevent strategic
behavior.

\begin{proposition} The process of deliberation over $|\alternatives| \geq 3$
	through deterministic deliberation procedure \({D}:
	\setOfStrictProfiles^n \to \setOfStrictProfiles^n\), followed by voting
	with voting rule $f$ cannot be surjective, strategyproof and
	non-dictatorial.

	\label{proposition:deterministic-delib} \end{proposition}

\begin{proofc} Assume, towards a contradiction, such a pair of deliberative
	procedure ($D$) and voting rule (\(f\)) exists. Any deterministic deliberation
	procedure $D$ could, in principle, be embedded into a voting rule
	$f'(\strictProfile) = f(D(\strictProfile))$, such that the voting rule
	simulates $D$ before applying $f$, which would result in  voting rule $f'$
	being surjective, strategyproof and non-dictatorial. This is a contradiction,
	by the Gibbard-Satterthwaite
	theorem~\citep{gibbardManipulationVotingSchemes1973,satterthwaiteStrategyproofnessArrowsConditions1975}.
\end{proofc}


We extend upon this result, showing the inclusion of biases in voters does not
mitigate the negative result. For this we define $\biasedDeliberation$ as
follows:

\begin{definition}{Biased Deliberation}{biased_delib} A deliberative procedure
	with biases $\biasedDeliberation : \setOfStrictProfiles ^ n \times
		\Reals_{[0,1]}^n \to \setOfStrictProfiles^n$ is an extension on a
	standard deliberative procedure. \(\biasedDeliberation\) has access to
	the bias each voter has towards their own opinion. \end{definition}

We now proceed with a corollary on
\Cref{proposition:deterministic-delib}. Towards this we assume biases
are true, in the sense that a voter cannot help but be `convinced' by
the presented profiles as much as their bias allows for this. We think
this assumption is weak and natural in the light of the current
model. Furthermore, a violation of this assumption would not imply the
following corollary to be false, instead the bias itself becomes a
point of strategy, allowing voters to pretend to be more hardheaded
than they in fact are.

\begin{corollary} A deliberative procedure with biases, followed by
	voting with any voting rule $f$, cannot be surjective,
	strategyproof and non-dictatorial

	\label{corollary:biased-delib} \end{corollary}

The proof of this follows from a reduction of the biased Deliberation
$\biasedDeliberation$ to general deliberation $D$.

\begin{proofc}{} Take any election consisting of biased deliberation
	$\biasedDeliberation$ and voting rule $f$, since biases
	$\boldsymbol{b}$ are true by assumption, they must be fixed,
	meaning that $\boldsymbol{b}$ is not reported but some fact of
	the matter. If this election was immune to strategic
	manipulation, then a deliberative procedure $D$ could embed
	this $b$, and simulate biased deliberation
	$\biasedDeliberation$, resulting in $D'(\strictProfile) =
		\biasedDeliberation(\strictProfile, \boldsymbol{b})$. As a
	direct corollary to \Cref{proposition:deterministic-delib},
	such a $D'$ cannot be surjective, strategyproof and
	non-dictatorial, showing a contradiction. \end{proofc}

This result is independent of the metric space chosen. From
here we now show that even if we take the deliberation
procedures on its own, it still not immune to strategic
manipulation. For this we restate strategyproofness as follows:

\begin{definition}{Strategyproofness of
		Deliberation}{delib-strategyproof} A deliberation
	procedure is strategyproof if there exists no voter $i$
	such that there is a profile $\strictProfile$, in which
	$i$ misreporting their preference $\Preference_{i}$ as
	$\Preference_{i}'$ results in the profile after
	deliberation $D(\strictProfile)$ is further from the
	$i$'s original preference than if they had reported
	$\Preference_{i}'$. This distance is measured as
	\[\operatorname{Dist}(\Preference_{i},
		D(\strictProfile)) \geq
		\operatorname{Dist}(\Preference_{i}, D(\strictProfile')).\]
	Where the Dist function is simply the sum of all distances
	between $\Preference_i$ and all preferences in
	$\strictProfile$. \end{definition}

One important note is that in the final profile, the
preferences of voter \(i\) might not be the same as it was
before the deliberation. That is why the distance is calculated
w.r.t. \(i\)'s original preference. Intuitively this could be
read as \(i\) misreporting their preference to prevent even
their own mind from being changed. Using this definition, we
show that the deliberative procedures, under the metric spaces
\emph{KS}, \emph{ DP}, \emph{ CS} are not strategyproof. Stated
as follows:

\begin{proposition}
	Deliberation, as defined by
	\citet{radDeliberationSinglePeakednessCoherent2021}, under distance
	measures \emph{KS}, \emph{ DP}, \emph{ CS} is not strategyproof, for $n
		\geq 2$ and $m \geq 3$.
\end{proposition}

We provide a proof by construction, we show how to do this for
the KS and DP distance measures, as they share the same profiles for this proof. The
proof for the CS distance measure is laid out in \Cref{AppendixA}.

\begin{proofc} Assume the following population: we
	have voter 1 whose bias is $1$, and all other voters $j \neq 1$
	have bias $0.5$. Furthermore, we have
	$\operatorname{Dist}(\Preference_1, \Preference_j) = 2$ for all
	$j$. Voter $1$ now has the option to report $\Preference_{1}'$
	instead, which has $\operatorname{Dist}(\Preference_{1}',
		\Preference_j) = 4$ and $\operatorname{Dist}(\Preference_{1}',
		\Preference_1) = 2$. If voter $1$ reports $\Preference_1'$,
	then all $j$ will update towards $1$'s true preference, as
	using \cref{eq:deliberation_step_formula} we get $r(R_{j},
		R_{1}', R_1) = 4$, while $r(R_{j}, R_{1}', R_j) = r(R_{j},
		R_{1}', R_1') = 16$.

	Resulting in $\operatorname{Dist}(R_{1},
		D(R_{1},\strictProfile_{-1})) = 2(n-1) >
		\operatorname{Dist}(R_{1}, D(R_{1}', \strictProfile_{-1})) =
		0$.

	Since 1 has a bias of 1, the order of the deliberation has no
	effect.

	We now show that for distance measures KS and DP, there exists
	these 3 preference orderings such that the necessary profile
	can be constructed. We use the following profiles: \[
		\begin{aligned} R_{1}' & = a \pref c \pref b \pref
                \cdots \pref m,                    \\ R_{1}  & = a \pref b \pref c
                \pref \cdots \pref m,              \\ R_{j}  & = b \pref a \pref c
                \pref \cdots \pref m.              \\\end{aligned} \]

	As we are only allowing strict preferences, both distance metrics
	behave the same locally, with the distance of two profiles being 2 whenever one
	is 1 swap of candidates away from the other. This means that  \(R_{i}\) and
	\(R_{j}\) have a distance of 2, as well as  \(R_{1}'\) and \(R_{1}\) having a
	distance of 2. In this case the total distance from \(R_{1}'\) to \(R_{j}\) is
	simply the sum of the local distances for both distance metrics, thus
	satisfying our requirements.\hfill \end{proofc}


These results show it is likely frivolous to attempt to design a strategy proof
deliberation procedure of the likes shown. Instead, focus is now brought to
modeling `ideal' deliberation, as laid out in \Cref{subsection:Meta-agreement}.
We provide the following mathematical formulations to the four tenants laid
out. \emph{Freedom}: voters can report any preference, \emph{Reason}: voters
are rational, \emph{Equality}: no voter has special rights, \emph{Consensus}:
voters deliberate aim to reach consensus. Which we extend with \emph{Honesty}:
Voters represent their true beliefs and preferences only.


\section{Our model} \label{sec: main model}

In an attempt to model meta-agreement through deliberation, our model needs to
make a proper distinction between the `substantive level' and the `meta level'.
In order to do so, we propose the following, let \(\policies = \{\policy_{1},
\cdots \policy_{k}\}\) denote the set of policies that could be implemented. A
voter $i \in \voters$, has support for these policies, represented as a number
on an interval over $\Reals$. At a meta level, a voter has an understanding of
which policies are supported by which candidates. This is modelled as matrix,
representing the estimated support for each policy for a candidate, thus voter
$i$ has $\EstSupport^i$, where $\EstSupport^i_{j, x}$ represents this voters'
estimated support of $\policy_j$ by candidate $x$.

This model does not explicitly model $D1$, the discovery of a common issue
dimension, on the one hand, if the candidates can be reduced to a line, this
model should be able to capture this, even if this one line crosses through
multiple issue dimension. For example if all issues are strongly (negatively)
correlated on the side of the candidates, but not on the voters, this model
allows for the voters to recognize this by properly estimating the
candidates' support matrices, while voters themselves can keep an
uncorrelated support vector. In the case that the actual issue dimension is
simply not included in $\policies$, our model would not be able to discover
this new dimension, even if human deliberation feasibly could. More
straightforwardly, if we the measured support is irrelevant to the true issue
dimension(s), our model cannot recover the true issue dimension.

Our model adapts the DeGroot learning model, which
originally models probability distributions. In that model, a voter is
a node in a graph, and deliberation can be modeled as a Markov chain. In our
model, we keep voters as nodes on a graph, as well as a Markov chain, however,
instead of a probability distribution, a voter has a support vector $S_i \in
	\Reals^{|\policies|}_{[0,1]}$, and estimated support matrix $\EstSupport_i\in
	\Reals^{|\alternatives| \times |\policies|}_{[0,1]}$.

Note that this does not mean that all policies have to have any (estimated)
support, nor that an candidate can only support a specific number of
policies, in principle there can be candidates that represent the status quo,
and thus do not support any policies, and there can be candidates that are
estimated to support all policies.  Let $\boldsymbol{S}= [\Support_1, \dots,
	\Support_{n}]^{T}$ denote the population opinion, which has shape \(|\voters|
\times |\policies|\).

In order to extract a ballot from this matrix, we assume a voter ranks the
candidates such that the most preferred candidate has the smallest distance
between the estimated support matrix for that candidate and her own. We
further allow this distance to be weighted, such that a voter may have one or
more policies their think are more important.

% Next we define the deliberative procedure, for which we will provide two
% models. Firstly a simpler model, which stays closer to the original DeGroot
% model, using only a transition matrix. Secondly we extend this model to be an
% Agent Based model, in which we allow agents to have additional properties. In
% both models we allow voters to deliberate on both their own support vector and
% the estimated support matrix, capturing deliberation on substantive basis as
% well as a meta basis, respectively.

Next we define the deliberative procedure in terms of the trust matrix of the
DeGroot model.

Firstly, a deliberative step can be modelled using a transition matrix $T$,
defined as follows: \[ T=\begin{bmatrix} t_{11} & \cdots & t_{1n} \\ \vdots &
                \ddots & \vdots          \\ t_{n1} & \cdots  & t_{nn} \\\end{bmatrix} \]

Here each $t_{ij}$ represents how much voter $i$ trusts the opinion of voter
$j$, in order for this to be a proper stochastic matrix, all rows must sum to
one, and have non-negative entries. Although this last requirement could be
seen as unrealistic, as a voter might actively distrust another voter and
update away from their opinion.

Using this, we can now model the opinions of voters after a deliberative step
as a matrix multiplication on some matrix $M$:

\begin{equation} M^{(1)} = TM^{(0)} \label{eq:update_degroot} \end{equation}

Each entry in the matrix then is simply a linear combination of the other
entries in that same column in $M^{(0)}$. In the case of $M = \EstSupport$,
this means that voter $i$'s support vector becomes a linear combination of all
support matrices, weighted by the trust in each voter. Deliberation can now be
modelled by taking powers of the trust matrix, $T^{t}$, representing $t$
deliberation steps. This matrix now represents how much each voter $i$ has
learned from the other voters, and can then be used to right multiply both the
support and the estimated support matrix to calculate a voters beliefs after
deliberation.

Finally, we provide an example of the first deliberation round in example
\ref{example:deGroot-delib}, since it is identical for both $\Support$ and
$\EstSupport$, we only show it for $\EstSupport$. The example also shows how
voters can initially agree on their support for policies, while disagreeing on
their preferred candidates, using meta-agreement to come to a consensus.

\begin{example}{DeGroot deliberation} {}

	We have voters \(\voters = \{1,2\}\), events \(\policies =
	\{\policy_{1}, \policy_{2}\}\), and candidates \(\alternatives =
	\{a,b\}\). The voters both think that \(\policy_{1} = 1, \policy_{2} =
	0\), meaning that they fully support the first policy and reject the
	second, they estimate the support by candidates as:

	\[
		\begin{array}{c|cc}
			1 & \policy_1 & \policy_2 \\ \hline
			a & 0.5       & 0         \\
			b & 0.5       & 1         \\
		\end{array}
		\hspace{1em}
		\begin{array}{c|cc}
			2 & \policy_1 & \policy_2 \\ \hline
			a & 1         & 0.9       \\
			b & 1         & 0.1       \\
		\end{array}
	\]

	Interpreting this matrix for both players on $\policy_1$ shows, voter 2 thinks $a$ and $b$ fully support $\policy_1$, while voter 1 thinks that $a$ and $b$  support $\policy_1$ less. We can encode this into the estimated support matrices as follows:

	\[ \EstSupport_1 =\begin{bmatrix} 0.5 & 0 \\
                0.5 & 1 \\\end{bmatrix}\quad
		\EstSupport_2 =\begin{bmatrix} 1 & 0.9
                \\ 1 & 0.1 \\\end{bmatrix} \]

	This results in voter 1 preferring candidate $b$ over candidate $a$, while
	voter 2, prefers $a$. Intuitively, since voter 1 thinks $\policy_{1}$ is
	equally supported by each candidate, while $\policy_{2}$ is not supported by
	$a$, it makes sense for them to prefer candidate $a$. Looking at the distances,
	we see that the absolute distance between voter 1 and candidate $a$ is 0.5,
	while for candidate $b$ it is 1.5. For voter 2 we see that the distance to
	$a$ is 0.9, while for candidate $b$ is it 0.1. Thus, voter 2 prefers $b$ to
	$a$.

	For the deliberation, we assume the following trust matrix:
	\[
		T= \begin{bmatrix}
			0.3 & 0.7 \\
			0.2 & 0.8
		\end{bmatrix}
	\]
	We get the following updated opinions:

	\begin{align*}
		\boldsymbol{\boldsymbol{\EstSupport}}^{(1)}
		 & =
		T\boldsymbol{\boldsymbol{\EstSupport}}^{(0)}
		\\ &
		=T\begin{bmatrix}\EstSupport_1
			  \EstSupport_2\end{bmatrix}^{T}
		\\ &
		=\begin{bmatrix}(0.3\EstSupport_1
			 + 0.7\EstSupport_{2}) &
			 (0.2\EstSupport_1 +
			 0.8\EstSupport_{2})\end{bmatrix}^{T} \\
		 & = \begin{bmatrix}
			     \begin{bmatrix}
				0.85 & 0.63
				\\
				0.85 & 0.37\end{bmatrix}
			      &
			     \begin{bmatrix}
				0.9 & 0.72
				\\ 0.9 & 0.18 \\
			\end{bmatrix}
		     \end{bmatrix}^{T}
	\end{align*}

	These new estimates are not yet in full consensus, meaning Meta-Agreement has not yet been reached.  Looking at their
	corresponding ballots, however, shows there is consensus on their most preferred candidate,
	as they both agree that candidates support $\policy_1$ equally, while $b$
	supports $\policy_2$ less.

	\label{example:deGroot-delib}
\end{example}


\subsection{Consensus} \label{sub: concensus DeGroot}

% \textcolor{RedViolet}{In using a single
% trust matrix for both support and
% estimated support matrices, we either have both
% meta and substantive agreement, or neither. But using
% two matrices would require justification, Maybe here we can
% introduce biases again, were we assume the original trust matrix, but
% we add some kind of "meta" bias and "substantive" bias, where these biases
% reflect how much they are willing to change their minds. In terms of analysis
% this would not really make things different, but for experimentation we might
% be able to argue that people might be more willing to change their views on the
% meta level, and we can experiment with lower substantive bias.}

Using this model of deliberation, meta-agreement can be seen as some shared estimated
support matrix over all policies. If the goal of deliberation is
meta-agreement, then the study of interest becomes the dynamics of convergence
towards a unified estimate. % Mention that this unified matrix, under this model, need not necessarily correspond to the "true" matrix.

We present a summary of results relating to strongly connected graphs, as well
as graphs for which there exists only closed and strongly connected subsets of
nodes. For other results we refer to \citet{golubNaiveLearningSocial2010}.
Firstly we focus on the strongly connected graphs.

\begin{proposition}{(\citet{golubNaiveLearningSocial2010}).} For a strongly
	connected matrix \(T\), the following properties are equivalent:
	\begin{itemize} \item[o] \(T\) is Convergent \item[o] \(T\) is
			Aperiodic \item[o] There exists a left eigenvector
			\(\boldsymbol{s}\) for matrix \(T\), with corresponding
			eigenvalue \(1\), whose entries sum to one, such that for every
			$P_i$, we have \[\left(\lim_{t\to \infty}T^{t}
				\boldsymbol{P}\right)_{i} = \boldsymbol{s}\boldsymbol{P}\]
	\end{itemize} \end{proposition}

This result is positive for studying the convergence dynamics, as no knowledge
of the initial distribution is needed to determine convergence, it allows us to
simply verify one of these three properties on the network. Though strongly
connected graphs might be a strong requirement, in the case of small scale (in
person) deliberation, this might be realistic. Fortunately, even outside this
setting it might be possible to reach convergence. For this we first define
what a closed set of nodes is.

\begin{definition}{Closed set of Nodes}{} A set of Nodes \(C = \{1, \dots,
	n\}\) is closed if for each \(i,j \in C\) we have $T_{ij} \geq 0$ and for each
	\(i \in C, j \notin C\) we have \(T_{ij} = 0\) \end{definition}

Using this definition, if each node is part of a closed set, we can form the
following proposition

\begin{proposition}{(\citet{golubNaiveLearningSocial2010}).} If for each \(i
	\in N\), \(i\) is a member of a closed set in the graph, and each closed set is
	strongly connected, \(T\) is convergent. \end{proposition}




\subsection{Voter Mapping} One might want to expand this model to capture
larger scale group dynamics, such as social networks. For this a reasonable
approach could be to gather data regarding the opinion of the general
population, and to map this onto a graph representing the communication in the
population.
For this we might want to find a bijection between the voters and the nodes such that
the difference between the shortest paths in the graph and the opinion distance is minimized.

We show that mapping voters to a graph as just described is NP-Hard, and the decision variant of the problem to be NP-Complete. We call this problem Distance-based Voter Mapping, and define it as follows.


\begin{problem}{$\delta$-DBVM($S$)}{dbvm}
{Given: $A, B \in S^{n \times n}, k\in\Reals_{\geq 0}$

Decision: Does there exist some bijection $f: [n] \to [n]$, such that: $$\delta(A, f(B)) \leq k$$}

Here we take $f(B)$ to mean the matrix $B'$ that is created when we take each $B'_{i,j} = B_{f(i),f(j)}$ and  $\delta$ is some distance function, $\delta: {S^{n \times n} \times S^{n \times n} \to \Reals_{\geq 0}}$.
\end{problem}

We will be needing the Quadratic assignment problem (QAP), we formulate a decision variant of QAP as follows.

\begin{problem}{QAP-Decision}{qap-decision}
{Given: $A, B \in S^{n \times n}, k\in\Reals_{\geq 0}$

Decision: Does there exist some bijection $f: [n] \to [n]$, such that: $$\sum_{i,j} A_{i,j}\cdot B_{f(i),f(j)} \geq k$$}
\end{problem}

\begin{theorem}
	$\delta$-DBVM($S$) is NP-Complete for $\delta\in\{\ell_1, \ell_2\}$ and $S = \{0,1\}^n$
	\label{thm:np_hard_voter_mapping_l2}
\end{theorem}


\begin{proofc}{}
	($\implies$ NP-Hard) The proof follows from a reduction to the Quadratic Assignment Decision Problem.

	Let $A$ be the matrix of pairwise distances between voters, and let $B$ be the matrix of shortest-path distances in the graph $G$, and $k$ be the $\delta$ achieved by the optimal bijection. $\ell_2$-DBVM($S$) requires finding a bijection $f$ that minimizes the $\ell_2$ objective:
	$$
		\sqrt{\sum_{i,j} \bigl(A_{i,j} - B_{f(i),f(j)}\bigr)^2}.
	$$
	Since the square root is a strictly increasing function, minimizing the expression above is equivalent to minimizing the sum inside:
	$$
		\sum_{i,j} (A_{i,j} - B_{f(i),f(j)})^2.
	$$
	Expanding the square gives:
	$$
		\sum_{i,j} A_{i,j}^2 - 2 A_{i,j} B_{f(i),f(j)} + B_{f(i),f(j)}^2.
	$$
	The terms $\sum A_{i,j}^2$ and $\sum B_{f(i),f(j)}^2$ are independent of $f$ (the former is fixed, the latter is a permutation of a fixed matrix), so the optimization reduces to:
	$$
		\max_f \sum_{i,j} A_{i,j} B_{f(i),f(j)},
	$$
	which is the standard form of the Quadratic Assignment Decision Problem. Note, $\max_f$ is a consequence of the sum being subtracted from the constants, thus we are still minimizing the total distance.

	Now we note that when $A$ and $B$ are in $S= \{0,1\}^{n \times n}$ , the
	$\ell_1$ and $\ell_2$ norms are identical. We also note that this binary
	domain would constitute a special instance of QAP, know as 0-1 Max-QAP, and
	is NP-Hard \cite{nagarajanMaximumQuadraticAssignment}. Thus solving
	$\delta$-DBVM($S$), on the binary domain, is equivalent to solving 0-1
	Max-QAP, and thus NP-Hard.~\checkmark


	($\implies$ NP-Complete) Given some $f$ and $k$, the decision can be made in $\mathcal{O}(n^2)$.~\checkmark


\end{proofc}

A concern with \Cref{thm:np_hard_voter_mapping_l2}, might be the matrices
containing certain patterns that might lead to an easier solution, though this
proof concerns itself with the worst-case and thus this possibility of this
problem being easier in practice is not issue. For this problem such patterns
seem unlikely to be of much help. We show one example to give an intuition for
this.

Take the case in which all voters hold one of 2 opinions, thus we can split
them into two groups of sizes $n, m$. Then the mapping algorithm
effectively requires finding a partition in the graph, that results in two
sub-graphs with exactly $n$ and $m$ nodes each. This is the
size-constrained graph partitioning problem, which is NP-Hard.

Thus, given that even under such a strong assumption the problem remains
computationally difficult, we suspect that patterns in the data are unlikely to
allow for easier exact solutions. This does leave room for approximation
algorithms, we do not present an overview of these, however under our
constraint of one of the matrices satisfying the triangle inequality, namely
the voter distance matrix. There exists a $\frac{2e}{e-1}$-approximation
algorithm \cite{nagarajanMaximumQuadraticAssignment}.

Despite these negative results, we attempted to enlist the help of a QAP-solver
\cite{virtanenSciPy10Fundamental2020} to find (approximate) solutions, using
the Fast Approximate QAP Algorithm
\cite{vogelsteinFastApproximateQuadratic2015}. Though, we find the solver does
not consistently find better solutions than random assignment, and is unable to
handle large enough instances for the experiments presented in the following
chapters.

% Given the number of
% simulations ran, it is infeasible to attempt to refine solutions to consistently
% be better than random solutions.
